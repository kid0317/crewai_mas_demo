"""
课程：02｜解构智能体：Agent 的解剖学与 ReAct 范式 示例代码
单 Agent 执行任务示例

演示如何使用 CrewAI 框架创建和配置一个完整的 Agent，包括：
1. Agent 的 Role、Goal、Backstory 定义（人设工程）
2. 工具集成（搜索、网页抓取、文件写入）
3. Task 和 Crew 的创建
4. Agent 执行任务的完整流程

本示例展示了一个网络调研专家 Agent，能够：
- 通过搜索工具收集信息
- 使用网页抓取工具获取详细内容
- 生成结构化的 Markdown 格式调研报告
- 将报告保存到本地文件

学习要点：
- Agent 的"人设工程"：如何通过 Role、Goal、Backstory 塑造 Agent 的专业能力
- 工具集成：如何为 Agent 配置合适的工具
- 任务执行：Agent 如何通过 ReAct 循环完成任务
"""

import sys
import os
from pathlib import Path

# 添加项目根目录到 Python 路径，以便能够导入项目模块
project_root = Path(__file__).resolve().parent.parent
print(project_root)
sys.path.insert(0, str(project_root))

from crewai import Agent, Task, Crew
from llm import aliyun_llm
from crewai_tools import ScrapeWebsiteTool, FileWriterTool, FileReadTool
from tools import BaiduSearchTool


# ==============================================================================
# Agent 定义：网络调研专家
# ==============================================================================
# 这是 Agent 的核心定义部分，展示了如何通过 Role、Goal、Backstory 来塑造 Agent 的专业能力
# Role：定义 Agent 的专业角色
# Goal：定义 Agent 的核心目标
# Backstory：定义 Agent 的专业背景和工作方法，这是"人设工程"的关键

searcher = Agent(
    role="网络调研专家",
    goal="通过系统化的网络搜索和信息提取，完成用户指定的调研任务，并生成结构化的Markdown格式调研报告写入文件",
    backstory="""你是一位经验丰富的网络调研专家，擅长通过系统化的方法收集、分析和整理网络信息。

你的工作流程遵循以下步骤：
1. **任务分析**：首先深入理解用户任务的意图和需求，明确调研目标和关键信息点
2. **搜索策略**：基于任务需求，生成多组精准的搜索关键词，确保覆盖不同角度和维度
3. **信息收集**：使用搜索工具获取初步结果，评估信息充分性；如信息不足，迭代生成新的搜索词进行补充搜索
4. **深度挖掘（强制要求）**：这是最关键的一步！搜索结果的摘要信息通常不够详细和完整，你必须：
   - 从每次搜索结果中，选择至少1-2个最相关、最权威的网页链接
   - **必须使用网页抓取工具（ScrapeWebsiteTool）**深入抓取这些网页的完整内容
   - 不要仅依赖搜索结果中的摘要，摘要信息往往不完整或过时
   - 对于重要信息点，必须抓取原始网页内容进行验证和补充
   - 抓取顺序：优先抓取官方网站、权威媒体、专业百科等高质量来源
5. **信息管理**：提取关键信息点时，必须记录三个要素：信息摘要、原文片段、原始网址，确保可追溯性
6. **报告撰写**：基于收集的信息点，撰写结构化的调研报告。报告必须：
   - 完全基于收集的事实信息，不添加未经验证的内容
   - 使用Markdown格式，结构清晰（标题、段落、列表等）
   - 在每个关键段落后添加引用链接，格式为：[原文](网址)
   - 确保引用链接准确对应信息来源
7. **分步审核**：每完成一个步骤，委托报告审核编辑审核，并根据意见修改
8. **报告整合**：整合所有步骤报告，生成完整的最终报告
9. **最终审核**：委托报告审核编辑进行最终审核，并根据意见修改
10. **文档保存**：为报告起一个描述性的文件名，保存为本地Markdown文档

**重要提醒**：
- 搜索工具返回的只是摘要，不是完整信息！你必须使用网页抓取工具获取详细内容
- 每次搜索后，必须至少抓取3-5个相关网页的完整内容
- 不要跳过抓取步骤，这是确保报告质量和准确性的关键
- 如果搜索结果中没有足够的相关链接，需要调整搜索策略重新搜索

你始终遵循准确性、完整性和可追溯性的原则，确保每份报告都有可靠的信息来源支撑。""",
    # 工具配置：为 Agent 提供完成任务所需的能力
    # ScrapeWebsiteTool：网页抓取工具，用于获取网页的完整内容
    # BaiduSearchTool：百度搜索工具，用于搜索网络信息
    # FileWriterTool：文件写入工具，用于保存调研报告
    tools=[ScrapeWebsiteTool(), BaiduSearchTool(), FileWriterTool()],
    memory=True,  # 启用记忆功能，Agent 可以记住之前的对话内容
    max_iter=100,  # 最大迭代次数，防止 Agent 陷入无限循环
    llm=aliyun_llm.AliyunLLM(
        model="qwen-plus",
        api_key=os.getenv("QWEN_API_KEY"),
        region="cn",  # 使用 region 参数，可选值: "cn", "intl", "finance"
    ),
)


# ==============================================================================
# Task 定义：调研任务
# ==============================================================================
# Task 定义了 Agent 需要完成的具体任务
# description：任务描述，告诉 Agent 要做什么
# expected_output：期望输出，告诉 Agent 应该产出什么格式的结果

task = Task(
    description="""帮我调研极客时间的相关信息，请分析这个研究任务，规划完成研究所需的步骤，并产出一份专业的调研报告。

**重要要求**：
1. 每次使用搜索工具后，必须从搜索结果中选择最相关的网页链接
2. **必须使用网页抓取工具（ScrapeWebsiteTool）**抓取这些网页的完整内容
3. 不要仅依赖搜索结果中的摘要信息，摘要往往不完整
4. 对于每个重要信息点，都要有对应的原始网页内容支撑
5. 优先抓取官方网站、权威媒体、专业百科等高质量来源""",
    expected_output="""完整的Markdown格式研究报告并写入文件，满足以下标准：

1. **内容完整性**：
   - 覆盖所有研究步骤和大纲章节
   - 每个关键信息点都有详细说明
   - 信息来源于抓取的完整网页内容，而非仅搜索摘要

2. **信息准确性**：
   - 所有信息点都有明确的引用来源
   - 引用格式正确：`[描述](URL)`
   - 引用链接可访问
   - 信息经过网页抓取验证，确保准确性

3. **结构规范性**：
   - 符合报告大纲结构
   - 章节层次清晰
   - Markdown格式正确

4. **质量保证**：
   - 经过分步审核和最终审核
   - 所有审核意见已处理
   - 达到发布质量标准
   - 报告基于抓取的详细网页内容，而非仅搜索摘要

输出文件：`{主题}-最终报告.md`""",
    agent=searcher,  # 指定执行任务的 Agent
)


# ==============================================================================
# Crew 定义：单 Agent 工作流
# ==============================================================================
# Crew 是 Agent 和 Task 的组织者，负责协调任务的执行
# 本示例是单 Agent 场景，Agent 独立完成任务

crew = Crew(
    agents=[searcher],  # 参与工作的 Agent 列表
    tasks=[task],  # 需要执行的任务列表
    verbose=True,  # 启用详细日志，可以看到 Agent 的思考过程
)


# ==============================================================================
# 执行任务
# ==============================================================================
# Crew.kickoff() 启动任务执行流程
# Agent 会按照 ReAct 循环（Reasoning + Acting）来完成任务：
# 1. 思考（Thought）：分析任务，决定下一步行动
# 2. 行动（Action）：调用工具执行操作
# 3. 观察（Observation）：获取工具执行结果
# 4. 重复上述步骤，直到得到最终答案

result = crew.kickoff()
print(result)